{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The document is in progress. Feel free to add more methods / links\n",
    "\n",
    "\n",
    "\n",
    "### Define Business goal\n",
    "\n",
    "### EDA\n",
    "    \n",
    "#### Note: for some of these methods preprocessing might be needed (e.g. missing values filling)\n",
    "    \n",
    "- Take a look into pandas_profiling.ProfileReport()/describe/value_count and so on\n",
    "- Look at distribution of features (sns.distplot, sns.violinplot)\n",
    "- Look at correlation between features (sns.heatmap(df.corr(), plt.scatter())\n",
    "- Look at duplicates (df.drop_duplicates())\n",
    "- Look at outliers (3-sigma, quantiles, histograms, scatter, DBscan)\n",
    "- Look at missing values\n",
    "- Try PCA/T-SNE\n",
    "\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "#### Dealing with missing values\n",
    "- Just drop rows with missing values\n",
    "- Drop the whole column if there are too many missing values\n",
    "- Impute with mean/median/most popular value\n",
    "- Impute with average value of nearest neighbours by other features\n",
    "- Train some model which predicts missing value based on other features\n",
    "- For categorical data might be used as a separate class\n",
    "- Факт наличия пропущенного значения тоже может нести информацию! \n",
    "- Для временных рядов можно оценить по предыдущим значениям\n",
    "\n",
    "#### Dealing with categorical variables\n",
    "\n",
    "- sklearn.preprocessing.LabelEncoder \n",
    "  encodes labels with value between 0 and n_classes - 1. might be used for algorithms like decision trees just to ensure it takes less space\n",
    "\n",
    "- sklearn.preprocessing.OneHotEncoder transforms to vectors [0,..0,1,0,...0]\n",
    "\n",
    "  might blow the dimensionality. tip: use PCA after it\n",
    "\n",
    "- sklearn.feature_extraction.FeatureHasher\n",
    "\n",
    "  hashing trick is good for features with high ordinality\n",
    "\n",
    "- Replace categorical feature with its count\n",
    "\n",
    "- Replace categorical feature with average value of target variable for regression task (or relative frequencies for classification tasks)\n",
    "\n",
    "  NOTE: it makes sense to use cross-validation for this task \n",
    "  (see discussion here https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/discussion/36136#201638)\n",
    "\n",
    "  some options are implemented in these libraries\n",
    "\n",
    "  https://tech.yandex.com/catboost/doc/dg/concepts/algorithm-main-stages_cat-to-numberic-docpage/\n",
    "\n",
    "  http://contrib.scikit-learn.org/categorical-encoding/targetencoder.html\n",
    "  \n",
    "\n",
    "\n",
    "#### Dealing with outliers \n",
    "\n",
    "- Drop rows with outliers\n",
    "- Apply the same methods as for missing values\n",
    "- Leave as is if you use methods like decision trees \n",
    "\n",
    "\n",
    "#### Dealing with skewed data\n",
    "\n",
    "- Apply mathematical transformations like log or Box-Cox (scipy.stats.boxcox)\n",
    "- Binning \n",
    "  Split data into bins and use bin number as a categorical feature. Quantiles might be used (pd.qcut)\n",
    "  \n",
    "  \n",
    "#### Standartization / Normalization\n",
    "\n",
    "###### Matters for most of models (exception are tree-based methods). Standartization makes sense for PCA as well\n",
    "\n",
    "- Standartization: subtract the mean and scale by std\n",
    "\n",
    "  sklearn.preprocessing.StandardScaler()\n",
    "\n",
    "- Normalization (divide by max)\n",
    "  \n",
    "  sklearn.preprocessing.normalize\n",
    "  \n",
    "- Min-max scaling: subtract min value and divide by (max-min)\n",
    "\n",
    "  sklearn.preprocessing.MinMaxScaler\n",
    "\n",
    "\n",
    "### Feature engineering:\n",
    "\n",
    "- Binary features \n",
    "\n",
    "  e.g. higher than mean or not. count is greater than zero or not\n",
    "  \n",
    "  some methods are in sklearn.preprocessing.Binarizer\n",
    "- Roundings\n",
    "\n",
    "  transform fractions to percents with a loose of precision (0.8531 -> 85). can be used as categorical feature\n",
    "  \n",
    "- Extract day/month/year from dates, feature is holiday\n",
    "\n",
    "- Aggregations:\n",
    "    \n",
    "    Calculate counts of an attribute (e.g. calculate number of appearance of each neighborhood in the dataset to estimate its size/density)\n",
    "    \n",
    "    Calculate avgs on an attribute (e.g. calculate average price of a house for each neighborhood)\n",
    "    \n",
    "- Adding polynomial features for linear models    \n",
    "\n",
    "  sklearn.preprocessing.PolynomialFeatures\n",
    "\n",
    "    \n",
    "- Apply PCA for highly correlated features\n",
    "\n",
    "- Clustering based features \n",
    "  \n",
    "  Do some clustering (perhaps of a part of attributes or some nested data) and use cluster number as a new categorical or average of target variable as a new numerical features\n",
    "\n",
    "- !Features based on domain knowledge\n",
    "\n",
    "  e.g. extract person age from birth date and current data, get distance to metro from house address\n",
    "  \n",
    "\n",
    "- Text data (haven't worked with it but here are just some basics)\n",
    "\n",
    "  feature_extraction.text.CountVectorizer\n",
    "  \n",
    "  feature_extraction.text.TfidfVectorizer\n",
    "  \n",
    "  word2vec/glove\n",
    "\n",
    "\n",
    "\n",
    "### Modelling:\n",
    "\n",
    "#### Simple model\n",
    "\n",
    "  - Linear models / Decision trees\n",
    "  - Grid search / Random Search / Cross-validation\n",
    "  - Metrics\n",
    "  - Feature importance\n",
    "  - Describe model\n",
    "\n",
    "#### Complicated model\n",
    "\n",
    "  - Boostings\n",
    "  - hyperopt\n",
    "  - Metrics\n",
    "  - Feature importance\n",
    "  - Describe model\n",
    "  \n",
    "  \n",
    "### Usefult tools\n",
    "\n",
    "http://scikit-learn.org/stable/modules/pipeline.html\n",
    "\n",
    "http://hyperopt.github.io/hyperopt/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
